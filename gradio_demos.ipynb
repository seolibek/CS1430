{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/timroelofs123/face_reaging/blob/main/notebooks/gradio_demos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8UPyx2FOi0bW"
   },
   "source": [
    "# Face Re-Aging Demos with Gradio; From the face_reaging repository. https://github.com/timroelofs123/face_reaging/blob/main/notebooks/gradio_demos.ipynb\n",
    "To try out the Gradio Demos using Google Colab, run the cells below.\n",
    "Be sure to select a runtime with GPU (e.g. `Runtime > Change Runtime Type > T4 (GPU)`) to make the model run fast.\n",
    "\n",
    "You can choose to either run the regular inference demo or the video demo. The demo will open in a new tab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V63jr7pmWMKX"
   },
   "source": [
    "## Downloading files and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Fl-OWpFqVLad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'face_reaging' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/timroelofs123/face_reaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ljqHF5EJWGoO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'face_re-aging' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://huggingface.co/timroelofs123/face_re-aging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Vawn2UimWajy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: rename face_re-aging/best_unet_model.pth to face_reaging/best_unet_model.pth: No such file or directory\n",
      "/Users/takumifujiwara/BrownAcademics/2024FallSemester/CSCI1430ComputerVision/FinalProject/CS1430/face_reaging\n"
     ]
    }
   ],
   "source": [
    "%mv face_re-aging/best_unet_model.pth face_reaging/\n",
    "%cd face_reaging/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OezK6WkeWz2G"
   },
   "source": [
    "## Installing requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "U29EGu-tW69J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[41 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m ================================================================================\n",
      "  \u001b[31m   \u001b[0m ================================================================================\n",
      "  \u001b[31m   \u001b[0m ================================================================================\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m                    CMake is not installed on your system!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m     Or it is possible some broken copy of cmake is installed on your system.\n",
      "  \u001b[31m   \u001b[0m     It is unfortunately very common for python package managers to include\n",
      "  \u001b[31m   \u001b[0m     broken copies of cmake.  So if the error above this refers to some file\n",
      "  \u001b[31m   \u001b[0m     path to a cmake file inside a python or anaconda or miniconda path then you\n",
      "  \u001b[31m   \u001b[0m     should delete that broken copy of cmake from your computer.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m     Instead, please get an official copy of cmake from one of these known good\n",
      "  \u001b[31m   \u001b[0m     sources of an official cmake:\n",
      "  \u001b[31m   \u001b[0m         - cmake.org (this is how windows users should get cmake)\n",
      "  \u001b[31m   \u001b[0m         - apt install cmake (for Ubuntu or Debian based systems)\n",
      "  \u001b[31m   \u001b[0m         - yum install cmake (for Redhat or CenOS based systems)\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m     On a linux machine you can run `which cmake` to see what cmake you are\n",
      "  \u001b[31m   \u001b[0m     actually using.  If it tells you it's some cmake from any kind of python\n",
      "  \u001b[31m   \u001b[0m     packager delete it and install an official cmake.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m     More generally, cmake is not installed if when you open a terminal window\n",
      "  \u001b[31m   \u001b[0m     and type\n",
      "  \u001b[31m   \u001b[0m        cmake --version\n",
      "  \u001b[31m   \u001b[0m     you get an error.  So you can use that as a very basic test to see if you\n",
      "  \u001b[31m   \u001b[0m     have cmake installed.  That is, if cmake --version doesn't run from the\n",
      "  \u001b[31m   \u001b[0m     same terminal window from which you are reading this error message, then\n",
      "  \u001b[31m   \u001b[0m     you have not installed cmake.  Windows users should take note that they\n",
      "  \u001b[31m   \u001b[0m     need to tell the cmake installer to add cmake to their PATH.  Since you\n",
      "  \u001b[31m   \u001b[0m     can't run commands that are not in your PATH.  This is how the PATH works\n",
      "  \u001b[31m   \u001b[0m     on Linux as well, but failing to add cmake to the PATH is a particularly\n",
      "  \u001b[31m   \u001b[0m     common problem on windows and rarely a problem on Linux.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m ================================================================================\n",
      "  \u001b[31m   \u001b[0m ================================================================================\n",
      "  \u001b[31m   \u001b[0m ================================================================================\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for dlib\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (dlib)\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gradio face_recognition antialiased_cnns kaleido av --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1uWzCNyXafL"
   },
   "source": [
    "## Running demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BTQxJNr2ipm_"
   },
   "source": [
    "Re-age your photo or video with the three demos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "P-ZLGAp82ewt"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gradio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgr\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UNet\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gradio'"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "from model.models import UNet\n",
    "from scripts.test_functions import process_image, process_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "izknf3I1XcyU"
   },
   "outputs": [],
   "source": [
    "# default settings\n",
    "window_size = 512\n",
    "stride = 256\n",
    "steps = 18\n",
    "frame_count = 100\n",
    "model_path = 'best_unet_model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "hHq3rGOVr0gQ"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# The code from this block equivalent to the \"run\" function in scripts.gradio_demo\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m unet_model \u001b[38;5;241m=\u001b[39m UNet()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m unet_model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(model_path, map_location\u001b[38;5;241m=\u001b[39mdevice))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# The code from this block equivalent to the \"run\" function in scripts.gradio_demo\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "unet_model = UNet().to(device)\n",
    "unet_model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "unet_model.eval()\n",
    "\n",
    "def block_img(image, source_age, target_age):\n",
    "    return process_image(unet_model, image, video=False, source_age=source_age,\n",
    "                          target_age=target_age, window_size=window_size, stride=stride)\n",
    "\n",
    "def block_img_vid(image, source_age):\n",
    "    return process_image(unet_model, image, video=True, source_age=source_age,\n",
    "                          target_age=0, window_size=window_size, stride=stride, steps=steps)\n",
    "\n",
    "def block_vid(video_path, source_age, target_age):\n",
    "    return process_video(unet_model, video_path, source_age, target_age,\n",
    "                          window_size=window_size, stride=stride, frame_count=frame_count)\n",
    "\n",
    "demo_img = gr.Interface(\n",
    "    fn=block_img,\n",
    "    inputs=[\n",
    "        gr.Image(type=\"pil\"),\n",
    "        gr.Slider(0, 90, value=20, step=1, label=\"Current age\", info=\"Choose your current age\"),\n",
    "        gr.Slider(0, 90, value=80, step=1, label=\"Target age\", info=\"Choose the age you want to become\")\n",
    "    ],\n",
    "    outputs=\"image\",\n",
    "    examples=[\n",
    "        ['UTK_processed/chosen_data/001_man_18_SA.jpg', 18, 50],\n",
    "        ['UTK_processed/chosen_data/001_woman_18_white.jpg', 18, 50],\n",
    "        ['UTK_processed/chosen_data/009_man_41_asian.jpg', 41, 80],\n",
    "        ['UTK_processed/chosen_data/009_woman_53_black.jpg', 53, 10],\n",
    "        ['UTK_processed/chosen_data/017_man_61_SA.jpg', 61, 15],\n",
    "        ['UTK_processed/chosen_data/017_woman_76_indigenous?viet?.jpg', 76, 15]\n",
    "    ],\n",
    "    description=\"Input an image of a person and age them from the source age to the target age.\"\n",
    ")\n",
    "\n",
    "demo_img_vid = gr.Interface(\n",
    "    fn=block_img_vid,\n",
    "    inputs=[\n",
    "        gr.Image(type=\"pil\"),\n",
    "        gr.Slider(0, 90, value=20, step=1, label=\"Current age\", info=\"Choose your current age\"),\n",
    "    ],\n",
    "    outputs=gr.Video(),\n",
    "    examples=[\n",
    "        ['UTK_processed/chosen_data/001_man_18_SA.jpg', 18],\n",
    "        ['UTK_processed/chosen_data/001_woman_18_white.jpg', 18],\n",
    "        ['UTK_processed/chosen_data/009_man_41_asian.jpg', 41],\n",
    "        ['UTK_processed/chosen_data/009_woman_53_black.jpg', 53],\n",
    "        ['UTK_processed/chosen_data/017_man_61_SA.jpg', 61],\n",
    "        ['UTK_processed/chosen_data/017_woman_76_indigenous?viet?.jpg', 76]\n",
    "    ],\n",
    "    description=\"Input an image of a person and a video will be returned of the person at different ages.\"\n",
    ")\n",
    "\n",
    "demo_vid = gr.Interface(\n",
    "    fn=block_vid,\n",
    "    inputs=[\n",
    "        gr.Video(),\n",
    "        gr.Slider(10, 90, value=20, step=1, label=\"Current age\", info=\"Choose your current age\"),\n",
    "        gr.Slider(10, 90, value=80, step=1, label=\"Target age\", info=\"Choose the age you want to become\")\n",
    "    ],\n",
    "    outputs=gr.Video(),\n",
    "    examples=[\n",
    "        ['UTK_processed/chosen_data/009_man_41_asian.jpg', 10, 80],\n",
    "    ],\n",
    "    description=\"Input a video of a person, and it will be aged frame-by-frame.\"\n",
    ")\n",
    "\n",
    "demo = gr.TabbedInterface([demo_img, demo_img_vid, demo_vid],\n",
    "                          tab_names=['Image inference demo', 'Image animation demo', 'Video inference demo'],\n",
    "                          title=\"Face Re-Aging Demo\",\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6q2f1hVB02t-"
   },
   "outputs": [],
   "source": [
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNIpPaQqNrwjCQA4O5O1DIt",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cs1430",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
